{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from string import punctuation\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download(\"averaged_perceptron_tagger\")\n",
    "# nltk.download(\"wordnet\")\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"maxent_ne_chunker\")\n",
    "# nltk.download(\"words\")\n",
    "# nltk.download(\"tagsets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/brianhung/Documents/myPython/Arc/data/job_postings_training_set.csv\"\n",
    "raw_data = pd.read_csv(path,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_id', 'title', 'location', 'department', 'salary_range',\n",
       "       'company_profile', 'description', 'requirements', 'benefits',\n",
       "       'telecommuting', 'has_company_logo', 'has_questions', 'employment_type',\n",
       "       'required_experience', 'required_education', 'industry', 'function',\n",
       "       'fraudulent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17828.000000</td>\n",
       "      <td>17828</td>\n",
       "      <td>17483</td>\n",
       "      <td>6314</td>\n",
       "      <td>2862</td>\n",
       "      <td>14538</td>\n",
       "      <td>17827</td>\n",
       "      <td>15140</td>\n",
       "      <td>10644</td>\n",
       "      <td>17828.000000</td>\n",
       "      <td>17828.000000</td>\n",
       "      <td>17828.000000</td>\n",
       "      <td>14370</td>\n",
       "      <td>10804</td>\n",
       "      <td>9755</td>\n",
       "      <td>12944</td>\n",
       "      <td>11395</td>\n",
       "      <td>17828.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11188</td>\n",
       "      <td>3097</td>\n",
       "      <td>1337</td>\n",
       "      <td>874</td>\n",
       "      <td>1707</td>\n",
       "      <td>14677</td>\n",
       "      <td>11881</td>\n",
       "      <td>6131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>131</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>English Teacher Abroad</td>\n",
       "      <td>GB, LND, London</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0-0</td>\n",
       "      <td>We help teachers get safe &amp;amp; secure jobs ab...</td>\n",
       "      <td>Play with kids, get paid for it Love travel? J...</td>\n",
       "      <td>University degree required. TEFL / TESOL / CEL...</td>\n",
       "      <td>See job description</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>Information Technology and Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>311</td>\n",
       "      <td>717</td>\n",
       "      <td>547</td>\n",
       "      <td>141</td>\n",
       "      <td>726</td>\n",
       "      <td>380</td>\n",
       "      <td>410</td>\n",
       "      <td>726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11588</td>\n",
       "      <td>3796</td>\n",
       "      <td>5131</td>\n",
       "      <td>1729</td>\n",
       "      <td>1743</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8914.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042966</td>\n",
       "      <td>0.795434</td>\n",
       "      <td>0.491979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.048351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5146.644635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.202786</td>\n",
       "      <td>0.403395</td>\n",
       "      <td>0.499950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.214513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4457.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8914.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13371.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17828.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              job_id                    title         location department  \\\n",
       "count   17828.000000                    17828            17483       6314   \n",
       "unique           NaN                    11188             3097       1337   \n",
       "top              NaN  English Teacher Abroad   GB, LND, London      Sales   \n",
       "freq             NaN                      311              717        547   \n",
       "mean     8914.500000                      NaN              NaN        NaN   \n",
       "std      5146.644635                      NaN              NaN        NaN   \n",
       "min         1.000000                      NaN              NaN        NaN   \n",
       "25%      4457.750000                      NaN              NaN        NaN   \n",
       "50%      8914.500000                      NaN              NaN        NaN   \n",
       "75%     13371.250000                      NaN              NaN        NaN   \n",
       "max     17828.000000                      NaN              NaN        NaN   \n",
       "\n",
       "       salary_range                                    company_profile  \\\n",
       "count          2862                                              14538   \n",
       "unique          874                                               1707   \n",
       "top             0-0  We help teachers get safe &amp; secure jobs ab...   \n",
       "freq            141                                                726   \n",
       "mean            NaN                                                NaN   \n",
       "std             NaN                                                NaN   \n",
       "min             NaN                                                NaN   \n",
       "25%             NaN                                                NaN   \n",
       "50%             NaN                                                NaN   \n",
       "75%             NaN                                                NaN   \n",
       "max             NaN                                                NaN   \n",
       "\n",
       "                                              description  \\\n",
       "count                                               17827   \n",
       "unique                                              14677   \n",
       "top     Play with kids, get paid for it Love travel? J...   \n",
       "freq                                                  380   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                             requirements  \\\n",
       "count                                               15140   \n",
       "unique                                              11881   \n",
       "top     University degree required. TEFL / TESOL / CEL...   \n",
       "freq                                                  410   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                   benefits  telecommuting  has_company_logo  has_questions  \\\n",
       "count                 10644   17828.000000      17828.000000   17828.000000   \n",
       "unique                 6131            NaN               NaN            NaN   \n",
       "top     See job description            NaN               NaN            NaN   \n",
       "freq                    726            NaN               NaN            NaN   \n",
       "mean                    NaN       0.042966          0.795434       0.491979   \n",
       "std                     NaN       0.202786          0.403395       0.499950   \n",
       "min                     NaN       0.000000          0.000000       0.000000   \n",
       "25%                     NaN       0.000000          1.000000       0.000000   \n",
       "50%                     NaN       0.000000          1.000000       0.000000   \n",
       "75%                     NaN       0.000000          1.000000       1.000000   \n",
       "max                     NaN       1.000000          1.000000       1.000000   \n",
       "\n",
       "       employment_type required_experience required_education  \\\n",
       "count            14370               10804               9755   \n",
       "unique               5                   7                 13   \n",
       "top          Full-time    Mid-Senior level  Bachelor's Degree   \n",
       "freq             11588                3796               5131   \n",
       "mean               NaN                 NaN                NaN   \n",
       "std                NaN                 NaN                NaN   \n",
       "min                NaN                 NaN                NaN   \n",
       "25%                NaN                 NaN                NaN   \n",
       "50%                NaN                 NaN                NaN   \n",
       "75%                NaN                 NaN                NaN   \n",
       "max                NaN                 NaN                NaN   \n",
       "\n",
       "                                   industry                function  \\\n",
       "count                                 12944                   11395   \n",
       "unique                                  131                      37   \n",
       "top     Information Technology and Services  Information Technology   \n",
       "freq                                   1729                    1743   \n",
       "mean                                    NaN                     NaN   \n",
       "std                                     NaN                     NaN   \n",
       "min                                     NaN                     NaN   \n",
       "25%                                     NaN                     NaN   \n",
       "50%                                     NaN                     NaN   \n",
       "75%                                     NaN                     NaN   \n",
       "max                                     NaN                     NaN   \n",
       "\n",
       "          fraudulent  \n",
       "count   17828.000000  \n",
       "unique           NaN  \n",
       "top              NaN  \n",
       "freq             NaN  \n",
       "mean        0.048351  \n",
       "std         0.214513  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17828 entries, 0 to 17827\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   job_id               17828 non-null  int64 \n",
      " 1   title                17828 non-null  object\n",
      " 2   location             17483 non-null  object\n",
      " 3   department           6314 non-null   object\n",
      " 4   salary_range         2862 non-null   object\n",
      " 5   company_profile      14538 non-null  object\n",
      " 6   description          17827 non-null  object\n",
      " 7   requirements         15140 non-null  object\n",
      " 8   benefits             10644 non-null  object\n",
      " 9   telecommuting        17828 non-null  int64 \n",
      " 10  has_company_logo     17828 non-null  int64 \n",
      " 11  has_questions        17828 non-null  int64 \n",
      " 12  employment_type      14370 non-null  object\n",
      " 13  required_experience  10804 non-null  object\n",
      " 14  required_education   9755 non-null   object\n",
      " 15  industry             12944 non-null  object\n",
      " 16  function             11395 non-null  object\n",
      " 17  fraudulent           17828 non-null  int64 \n",
      "dtypes: int64(5), object(13)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>job_id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003990</td>\n",
       "      <td>-0.014058</td>\n",
       "      <td>-0.086643</td>\n",
       "      <td>0.079736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telecommuting</th>\n",
       "      <td>-0.003990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.020094</td>\n",
       "      <td>0.019998</td>\n",
       "      <td>0.034770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_company_logo</th>\n",
       "      <td>-0.014058</td>\n",
       "      <td>-0.020094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.234263</td>\n",
       "      <td>-0.261673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_questions</th>\n",
       "      <td>-0.086643</td>\n",
       "      <td>0.019998</td>\n",
       "      <td>0.234263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.091578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraudulent</th>\n",
       "      <td>0.079736</td>\n",
       "      <td>0.034770</td>\n",
       "      <td>-0.261673</td>\n",
       "      <td>-0.091578</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    job_id  telecommuting  has_company_logo  has_questions  \\\n",
       "job_id            1.000000      -0.003990         -0.014058      -0.086643   \n",
       "telecommuting    -0.003990       1.000000         -0.020094       0.019998   \n",
       "has_company_logo -0.014058      -0.020094          1.000000       0.234263   \n",
       "has_questions    -0.086643       0.019998          0.234263       1.000000   \n",
       "fraudulent        0.079736       0.034770         -0.261673      -0.091578   \n",
       "\n",
       "                  fraudulent  \n",
       "job_id              0.079736  \n",
       "telecommuting       0.034770  \n",
       "has_company_logo   -0.261673  \n",
       "has_questions      -0.091578  \n",
       "fraudulent          1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **'job_id': --int**  \n",
    "不處理\n",
    "- **'title': --text**  \n",
    "The title of the job ad entry  \n",
    "toDo:分離title詞向量做cosine similarity後分群，群數為10？要測試\n",
    "- **'location': --text**  \n",
    "Geographical location of the job ad  \n",
    "分離出「country」、「state」、「location」、...\n",
    "- **'department': --text**  \n",
    "Corporate department (e.g. sales)  \n",
    "toDo\n",
    "- **'salary_range': --text**  \n",
    "Indicative salary range (e.g. $50,000-$60,000)  \n",
    "分離薪資上下限 e.g. 90000-150000 -> min_salary:90000,max_salary:150000\n",
    "- **'company_profile': --text**  \n",
    "A brief company description  \n",
    "方法toDo\n",
    "- **'description': --text**  \n",
    "The details description of the job ad  \n",
    "方法toDo\n",
    "- **'requirements': --text**  \n",
    "Enlisted requirements for the job opening  \n",
    "方法toDo\n",
    "- **'benefits': --text**  \n",
    "Enlisted offered benefits by the employer  \n",
    "方法toDo\n",
    "- **'telecommuting': --bool**  \n",
    "True for telecommuting positions  \n",
    "[0,1]\n",
    "- **'has_company_logo': --bool**  \n",
    "True if company logo is present  \n",
    "[0,1]\n",
    "- **'has_questions': --bool**  \n",
    "True if screening questions are present  \n",
    "[0,1]\n",
    "- **'employment_type': --text**  \n",
    "Full-type, Part-time, Contract, etc  \n",
    "['Contract', 'Full-time', 'Other', 'Part-time', 'Temporary',None]\n",
    "- **'required_experience': --text**  \n",
    "Executive, Entry level, Intern, etc  \n",
    "['Associate', 'Director', 'Entry level', 'Executive', 'Internship', 'Mid-Senior level', 'Not Applicable']\n",
    "- **'required_education': --text**  \n",
    "Doctorate, Master’s Degree, Bachelor, etc  \n",
    "['Associate Degree', 'Bachelor's Degree', 'Certification', 'Doctorate', 'High School or equivalent', 'Master's Degree', 'Professional', 'Some College Coursework Completed', 'Some High School Coursework', 'Unspecified', 'Vocational', 'Vocational - Degree', 'Vocational - HS Diploma']\n",
    "- **'industry': --text**  \n",
    "Automotive, IT, Health care, Real estate, etc  \n",
    "['Accounting', 'Airlines/Aviation', 'Alternative Dispute Resolution', 'Animation', 'Apparel & Fashion', 'Architecture & Planning', 'Automotive', 'Aviation & Aerospace', 'Banking', 'Biotechnology',  \n",
    "...  \n",
    "'Translation and Localization', 'Transportation/Trucking/Railroad', 'Utilities', 'Venture Capital & Private Equity', 'Veterinary', 'Warehousing', 'Wholesale', 'Wine and Spirits', 'Wireless', 'Writing and Editing']\n",
    "- **'function': --text**  \n",
    "Consulting, Engineering, Research, Sales etc  \n",
    "功能性?市場 -> 跟column['department']類似?\n",
    "- **'fraudulent': --int**  \n",
    "[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "後續可以用各國location data 過濾資料\n",
    "\"\"\"\n",
    "location_data = raw_data[['job_id','location']].copy()\n",
    "\n",
    "# Fill NaN and non-string -> ''\n",
    "location_data['location'] = [i if type(i)==str else '' for i in location_data['location']]\n",
    "\n",
    "# Split the location data into list() -> location['loc_list']\n",
    "loc_list = []\n",
    "for i in range(len(location_data)):\n",
    "    tmp = location_data['location'][i]\n",
    "    if tmp == '':\n",
    "        loc_list.append('')\n",
    "        continue\n",
    "\n",
    "    tmp_loc = tmp.split(sep = ',', maxsplit = -1)\n",
    "\n",
    "    # drop empty string and trim(strip)\n",
    "    tmp_loc = [i.strip() for i in tmp_loc if i.strip() != '']\n",
    "    loc_list.append(tmp_loc)\n",
    "\n",
    "location_data['loc_list'] = loc_list\n",
    "\n",
    "# Use set() to save all the locations in loc_set\n",
    "loc_set = set()\n",
    "for i in loc_list:\n",
    "    loc_set.update(i)\n",
    "    \n",
    "# location_data explode all locations to columns\n",
    "location_data = pd.concat([location_data,pd.DataFrame(columns=list(loc_set))])\n",
    "location_data = location_data.fillna(0)\n",
    "\n",
    "# Update the location data from row\n",
    "for i in range(len(location_data)):\n",
    "    one_loc_list = location_data.loc[i,'loc_list']\n",
    "    for loc in one_loc_list:\n",
    "        location_data.loc[i,loc] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. 後續可用job_title,job_description,industry,function...等欄位填補NaN\n",
    "2. 若有對應的\"職稱library\",可簡化職稱資料\n",
    "   e.g. kaggle job title library?\n",
    "\"\"\"\n",
    "\n",
    "department_data = raw_data[['job_id','department']].copy()\n",
    "\n",
    "# Fill NaN and non-string -> ''\n",
    "department_data['department'] = [i if type(i)==str else '' for i in department_data['department']]\n",
    "\n",
    "# Use set() to save all the departments in dep_set\n",
    "dep_list = list(department_data['department'])\n",
    "dep_set = set()\n",
    "dep_set.update(dep_list)\n",
    "\n",
    "# Clean type of int data -> ''\n",
    "for i in range(len(department_data)):\n",
    "    try:\n",
    "        int(department_data.loc[i,'department'])\n",
    "        department_data.loc[i,'department'] = ''\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - salary_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_salary(salary_list):\n",
    "    \"\"\"\n",
    "    Check if salary_list's elements is all Numbers\n",
    "    \"\"\"\n",
    "    rel = True\n",
    "    for i in salary_list:\n",
    "        if not i.isnumeric():\n",
    "            rel = False\n",
    "    return rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "後續若有薪資水平評估，可依salary range做薪水高低的分類\n",
    "\"\"\"\n",
    "salary_data = raw_data[['job_id','salary_range']].copy()\n",
    "\n",
    "# Fill NaN and non-string -> '0-0'\n",
    "salary_data['salary_range'] = [i if type(i)==str else '0-0' for i in salary_data['salary_range']]\n",
    "\n",
    "# ToDo: description\n",
    "min_salary = []\n",
    "max_salary = []\n",
    "avg_salary = []\n",
    "for i in range(len(salary_data)):\n",
    "    tmp_rel = ['0','0','0'] #[tmp_min, tmp_max, tmp_avg]\n",
    "    tmp = salary_data['salary_range'][i]\n",
    "    tmp_salary = tmp.split(sep = '-', maxsplit = -1)\n",
    "    \n",
    "    if check_salary(tmp_salary):\n",
    "        if len(tmp_salary) == 1:\n",
    "            tmp_rel = [int(tmp_salary[0])]*3\n",
    "        if len(tmp_salary) == 2:\n",
    "            tmp_rel = tmp_salary + [str(int((int(tmp_min) + int(tmp_max))/2))]\n",
    "    \n",
    "    min_salary.append(tmp_rel[0])\n",
    "    max_salary.append(tmp_rel[1])\n",
    "    avg_salary.append(tmp_rel[2])\n",
    "\n",
    "salary_data['min_salary'] = min_salary\n",
    "salary_data['max_salary'] = max_salary\n",
    "salary_data['avg_salary'] = avg_salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text mining with nltk & tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk NER table\n",
    "# nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - clean data & cut word function set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for cleaning data\n",
    "def remove_urls(s):\n",
    "    s = re.sub('[^\\s]*.com[^\\s]*', \"\", s)\n",
    "    s = re.sub('[^\\s]*www.[^\\s]*', \"\", s)\n",
    "    s = re.sub('[^\\s]*.co.uk[^\\s]*', \"\", s)\n",
    "    return s\n",
    "\n",
    "def remove_star_words(s):\n",
    "    return re.sub('[^\\s]*[\\*]+[^\\s]*', \"\", s)\n",
    "\n",
    "def remove_nums(s):\n",
    "    return re.sub('[^\\s]*[0-9]+[^\\s]*', \"\", s)\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    \"\"\"\n",
    "    1. Cutumize replace the dash '-' -> ' '\n",
    "    2. Replace other symbols -> ''\n",
    "    \"\"\"\n",
    "    s = s.replace('-',' ')\n",
    "    s = s.replace('–','')\n",
    "    global punctuation\n",
    "    for p in punctuation:\n",
    "        s = s.replace(p, '')\n",
    "\n",
    "    return s\n",
    "\n",
    "def convert_lower_case(s):\n",
    "    return s.lower()\n",
    "\n",
    "def remove_stopwords(s):\n",
    "    global en_stopwords\n",
    "    s = word_tokenize(s)\n",
    "    s = \" \".join([w for w in s if w not in en_stopwords])\n",
    "    return s\n",
    "\n",
    "def filter_text(s):\n",
    "    \"\"\"\n",
    "    Filter text with ADJ,VERB,NOUN,ADV\n",
    "    \"\"\"\n",
    "    #tokenize words\n",
    "    tokenized_corpus = nltk.word_tokenize(s)\n",
    "    \n",
    "    # Lemmatizer(字型還原)\n",
    "    lemmatized_tokens = [lmtzr.lemmatize(token) for token in tokenized_corpus]\n",
    "    \n",
    "    # 詞性標記\n",
    "    pos = nltk.pos_tag(lemmatized_tokens)\n",
    "    \n",
    "    wordnet_pos = []\n",
    "    for p in pos:\n",
    "        word, tag = p\n",
    "        if tag.startswith('J'):\n",
    "            wordnet_pos.append(nltk.corpus.wordnet.ADJ)\n",
    "        elif tag.startswith('V'):\n",
    "            wordnet_pos.append(nltk.corpus.wordnet.VERB)\n",
    "        elif tag.startswith('N'):\n",
    "            wordnet_pos.append(nltk.corpus.wordnet.NOUN)\n",
    "        elif tag.startswith('R'):\n",
    "            wordnet_pos.append(nltk.corpus.wordnet.ADV)\n",
    "        else:\n",
    "            wordnet_pos.append('')\n",
    "    \n",
    "    # Lemmatizer(字型還原)\n",
    "    lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "    tokens_le = [lemmatizer.lemmatize(pos[i][0], pos=wordnet_pos[i]) \n",
    "                 for i in range(len(pos)) if wordnet_pos[i] != '']\n",
    "    \n",
    "    return tokens_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_clean_data(df):\n",
    "    \"\"\"\n",
    "    Mainly function to clean data and EDA with nltk.\n",
    "    input: Pandas DataFrame with one column\n",
    "    output: Pandas DataFrame with one column\n",
    "    \"\"\"\n",
    "    clean_data = df\n",
    "    en_stopwords = stopwords.words('english') + ['’','amp']\n",
    "\n",
    "    fun_clean_data_list = [remove_urls,\n",
    "                           remove_star_words,\n",
    "                           remove_nums,\n",
    "                           remove_punctuation,\n",
    "                           convert_lower_case,\n",
    "                           remove_stopwords,\n",
    "                           filter_text\n",
    "                          ]\n",
    "    \n",
    "    for func in fun_clean_data_list:\n",
    "        clean_data = clean_data.map(func)\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Use NB to predict the loss ['title'] from other column \n",
    "like ['company_profile','description','requirements',...]\n",
    "\"\"\"\n",
    "title_data = raw_data[['job_id','title']]\n",
    "\n",
    "# Fill NaN\n",
    "title_data = title_data.fillna('')\n",
    "\n",
    "# Clean and cut word\n",
    "title_data['clean_text_tag'] = main_clean_data(title_data['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - company_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_profile_data = raw_data[['job_id','company_profile']]\n",
    "\n",
    "# Fill NaN\n",
    "company_profile_data = company_profile_data.fillna('')\n",
    "\n",
    "# Clean and cut word\n",
    "company_profile_data['clean_text_tag'] = main_clean_data(company_profile_data['company_profile'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_data = raw_data[['job_id','description']]\n",
    "\n",
    "# Fill NaN\n",
    "description_data = description_data.fillna('')\n",
    "\n",
    "# Clean and cut word\n",
    "description_data['clean_text_tag'] = main_clean_data(description_data['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - toDo: description 的 TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF\n",
    "# 10 most common words in the job description\n",
    "# import the necessary functions from the nltk library\n",
    "\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "# prepare corpus from the descriptions that dont have stopwords\n",
    "# tmp_description = description_data['description'].tolist()\n",
    "# tmp_description = [i if type(i)==str else '' for i in tmp_description ]\n",
    "corpus = \" \".join(description_data['clean_full_description_no_stop'].tolist())\n",
    "\n",
    "#tokenize words\n",
    "tokenized_corpus = nltk.word_tokenize(corpus)\n",
    "\n",
    "# lemmatize these tokens\n",
    "lemmatized_tokens = [lmtzr.lemmatize(token) for token in tokenized_corpus]\n",
    "\n",
    "\n",
    "\n",
    "# grammer - <NN>* or <JJ>*<NN>\n",
    "# grammer = r\"\"\"\n",
    "#           NP: {<JJ>*<NN>}   # chunk determiner/possessive, adjectives and noun\n",
    "#               {<NNP>+}                # chunk sequences of proper nouns\n",
    "#           \"\"\"\n",
    "# cp = nltk.RegexpParser(grammar)\n",
    "# sentence = [(\"Rapunzel\", \"NNP\"), (\"let\", \"VBD\"), (\"down\", \"RP\"), [1]\n",
    "#                  (\"her\", \"PP$\"), (\"long\", \"JJ\"), (\"golden\", \"JJ\"), (\"hair\", \"NN\")]\n",
    "\n",
    "# word frequencies for the lemmatized tokens\n",
    "fd = nltk.FreqDist(lemmatized_tokens)\n",
    "\n",
    "# get the top words\n",
    "top_words = []\n",
    "for key, value in fd.items():\n",
    "    top_words.append((key, value))\n",
    "\n",
    "# sort the list by the top frequencies\n",
    "top_words = sorted(top_words, key = lambda x:x[1], reverse = True)\n",
    "\n",
    "# keep top 10 words only\n",
    "top_10_words = top_words[:10]\n",
    "\n",
    "top_10_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements_data = raw_data[['job_id','requirements']]\n",
    "\n",
    "# Fill NaN\n",
    "requirements_data = requirements_data.fillna('')\n",
    "\n",
    "# Clean and cut word\n",
    "requirements_data['clean_text_tag'] = main_clean_data(requirements_data['requirements'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "benefits_data = raw_data[['job_id','benefits']]\n",
    "# Fill NaN\n",
    "benefits_data = benefits_data.fillna('')\n",
    "\n",
    "# Clean and cut word\n",
    "benefits_data['clean_text_tag'] = main_clean_data(benefits_data['benefits'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - telecommuting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecommuting_data = raw_data[['job_id','telecommuting']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - has_company_logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_company_logo_data = raw_data[['job_id','has_company_logo']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - has_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_questions_data = raw_data[['job_id','has_questions']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - employment_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_type_data = raw_data[['job_id','employment_type']].copy()\n",
    "\n",
    "# Fill NaN and non-string -> 'Unknown'\n",
    "employment_type_data['employment_type'] = [i if type(i)==str else 'Unknown' \n",
    "                                           for i in employment_type_data['employment_type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - required_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_experience_data = raw_data[['job_id','required_experience']].copy()\n",
    "\n",
    "# Fill NaN and non-string -> 'Unknown'\n",
    "required_experience_data['required_experience'] = [i if type(i)==str else 'Unknown' \n",
    "                                                   for i in required_experience_data['required_experience']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - required_education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. 這裡的null值，不一定是資料中的'Unspecified'，所以歸類為'Unknown'\n",
    "2. 可能可以從job desciption中回填,但需要education的詞庫\n",
    "\"\"\"\n",
    "required_education_data = raw_data[['job_id','required_education']].copy()\n",
    "\n",
    "# Fill NaN and non-string -> 'Unknown'\n",
    "required_education_data['required_education'] = [i if type(i)==str else 'Unknown' for i in required_education_data['required_education']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. 這裡的null值，歸類為'Unknown'\n",
    "2. 可能可以從job desciption中回填,但需要industry的詞庫\n",
    "\"\"\"\n",
    "industry_data = raw_data[['job_id','industry']].copy()\n",
    "\n",
    "# Fill NaN and non-string -> 'Unknown'\n",
    "industry_data['industry'] = [i if type(i)==str else 'Unknown' for i in industry_data['industry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. 這裡的null值，歸類為'Unknown'\n",
    "2. 可能可以從job desciption中回填,但需要industry的詞庫\n",
    "\"\"\"\n",
    "function_data = raw_data[['job_id','function']].copy()\n",
    "\n",
    "# Fill NaN and non-string -> 'Unknown'\n",
    "# function_data['function'] = [i if type(i)==str else 'Unknown' for i in function_data['function']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
